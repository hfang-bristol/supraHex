% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sTrainSeq.r
\name{sTrainSeq}
\alias{sTrainSeq}
\title{Function to implement training via sequential algorithm}
\usage{
sTrainSeq(sMap, data, sTrain, seed = 825, verbose = TRUE)
}
\arguments{
\item{sMap}{an object of class "sMap" or "sInit"}

\item{data}{a data frame or matrix of input data}

\item{sTrain}{an object of class "sTrain"}

\item{seed}{an integer specifying the seed}

\item{verbose}{logical to indicate whether the messages will be
displayed in the screen. By default, it sets to TRUE for display}
}
\value{
an object of class "sMap", a list with following components:
\itemize{
\item{\code{nHex}: the total number of hexagons/rectanges in the grid}
\item{\code{xdim}: x-dimension of the grid}
\item{\code{ydim}: y-dimension of the grid}
\item{\code{r}: the hypothetical radius of the grid}
\item{\code{lattice}: the grid lattice}
\item{\code{shape}: the grid shape}
\item{\code{coord}: a matrix of nHex x 2, with each row corresponding
to the coordinates of a hexagon/rectangle in the 2D map grid}
\item{\code{ig}: the igraph object}
\item{\code{init}: an initialisation method}
\item{\code{neighKernel}: the training neighborhood kernel}
\item{\code{codebook}: a codebook matrix of nHex x ncol(data), with
each row corresponding to a prototype vector in input high-dimensional
space}
\item{\code{call}: the call that produced this result}
}
}
\description{
\code{sTrainSeq} is supposed to perform sequential training algorithm.
It requires three inputs: a "sMap" or "sInit" object, input data, and a
"sTrain" object specifying training environment. The training is
implemented iteratively, each training cycle consisting of: i) randomly
choose one input vector; ii) determine the winner hexagon/rectangle
(BMH) according to minimum distance of codebook matrix to the input
vector; ii) update the codebook matrix of the BMH and its neighbors via
updating formula (see "Note" below for details). It also returns an
object of class "sMap".
}
\note{
Updating formula is: \eqn{m_i(t+1) = m_i(t) +
\alpha(t)*h_{wi}(t)*[x(t)-m_i(t)]}, where
\itemize{
\item{\eqn{t} denotes the training time/step}
\item{\eqn{i} and \eqn{w} stand for the hexagon/rectangle \eqn{i} and
the winner BMH \eqn{w}, respectively}
\item{\eqn{x(t)} is an input vector randomly choosen (from the input
data) at time \eqn{t}}
\item{\eqn{m_i(t)} and \eqn{m_i(t+1)} are respectively the prototype
vectors of the hexagon \eqn{i} at time \eqn{t} and \eqn{t+1}}
\item{\eqn{\alpha(t)} is the learning rate at time \eqn{t}. There are
three types of learning rate functions:}
\itemize{
\item{For "linear" function, \eqn{\alpha(t)=\alpha_0*(1-t/T)}}
\item{For "power" function,
\eqn{\alpha(t)=\alpha_0*(0.005/\alpha_0)^{t/T}}}
\item{For "invert" function, \eqn{\alpha(t)=\alpha_0/(1+100*t/T)}}
\item{Where \eqn{\alpha_0} is the initial learing rate (typically,
\eqn{\alpha_0=0.5} at "rough" stage, \eqn{\alpha_0=0.05} at "finetune"
stage), \eqn{T} is the length of training time/step (often being set to
input data length, i.e., the total number of rows)}
}
\item{\eqn{h_{wi}(t)} is the neighborhood kernel, a non-increasing
function of i) the distance \eqn{d_{wi}} between the hexagon/rectangle
\eqn{i} and the winner BMH \eqn{w}, and ii) the radius \eqn{\delta_t}
at time \eqn{t}. There are five kernels available:}
\itemize{
\item{For "gaussian" kernel,
\eqn{h_{wi}(t)=e^{-d_{wi}^2/(2*\delta_t^2)}}}
\item{For "cutguassian" kernel,
\eqn{h_{wi}(t)=e^{-d_{wi}^2/(2*\delta_t^2)}*(d_{wi} \le \delta_t)}}
\item{For "bubble" kernel, \eqn{h_{wi}(t)=(d_{wi} \le \delta_t)}}
\item{For "ep" kernel, \eqn{h_{wi}(t)=(1-d_{wi}^2/\delta_t^2)*(d_{wi}
\le \delta_t)}}
\item{For "gamma" kernel,
\eqn{h_{wi}(t)=1/\Gamma(d_{wi}^2/(4*\delta_t^2)+2)}}
}
}
}
\examples{
# 1) generate an iid normal random matrix of 100x10 
data <- matrix( rnorm(100*10,mean=0,sd=1), nrow=100, ncol=10)

# 2) from this input matrix, determine nHex=5*sqrt(nrow(data))=50, 
# but it returns nHex=61, via "sHexGrid(nHex=50)", to make sure a supra-hexagonal grid
sTopol <- sTopology(data=data, lattice="hexa", shape="suprahex")

# 3) initialise the codebook matrix using "uniform" method
sI <- sInitial(data=data, sTopol=sTopol, init="uniform")

# 4) define trainology at "rough" stage
sT_rough <- sTrainology(sMap=sI, data=data, algorithm="sequential",
stage="rough")

# 5) training at "rough" stage
sM_rough <- sTrainSeq(sMap=sI, data=data, sTrain=sT_rough)

# 6) define trainology at "finetune" stage
sT_finetune <- sTrainology(sMap=sI, data=data, algorithm="sequential",
stage="finetune")

# 7) training at "finetune" stage
sM_finetune <- sTrainSeq(sMap=sM_rough, data=data, sTrain=sT_rough)
}
\seealso{
\code{\link{sTrainology}}, \code{\link{visKernels}}
}
